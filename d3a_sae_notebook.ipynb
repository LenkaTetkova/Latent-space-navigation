{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1bf0c2d4",
      "metadata": {
        "id": "1bf0c2d4"
      },
      "source": [
        "# Sparse Autoencoders for model steering\n",
        "Authored by Mikkel Godsk JÃ¸rgensen (mgojo@dtu.dk)\n",
        "\n",
        "In this notebook, we will explore using sparse autoencoders (abbr.: *SAEs*) for model steering in a similar fashion to [Templeton et al., 2024](https://transformer-circuits.pub/2024/scaling-monosemanticity/). We will be using the Gemma-2-2b model by Google [(Riviere et al., 2024)](https://arxiv.org/pdf/2408.00118), and the Gemma-Scope suite by DeepMind [(Lieberum et al., 2024)](https://arxiv.org/pdf/2408.05147).\n",
        "\n",
        "A sparse autoencoder is a shallow autoencoder with a wide intermediate layer subject to a sparsity constraint/incentive. The Gemma-Scope architecture is as follows:\n",
        "$$\n",
        "\\begin{split}\n",
        "    \\textbf{Encoder:}\\quad\\quad\\boldsymbol{f}(\\boldsymbol{x})&=\\sigma(\\boldsymbol{W}_{\\rm enc}\\boldsymbol{x}+\\boldsymbol{b}_{\\rm enc})\\\\\n",
        "    \\textbf{Decoder:}\\quad\\quad\\boldsymbol{g}(\\boldsymbol{f})&=\\boldsymbol{W}_{\\rm dec}\\boldsymbol{f}+\\boldsymbol{b}_{\\rm dec}.\n",
        "\\end{split}\n",
        "$$\n",
        "Here the input $\\boldsymbol{x}\\in\\mathbb{R}^n$ is an internal representation from the model subject to investigation/steering (i.e. Gemma 2), $\\boldsymbol{f}(\\boldsymbol{x})\\in\\mathbb{R}^M$ with $M\\gg n$ is a vector of so-called *feature activations*, and $\\hat{\\boldsymbol{x}}=\\boldsymbol{g}(\\boldsymbol{f}(\\boldsymbol{x}))\\in\\mathbb{R}^n$ is the reconstruction of the internal representation.\n",
        "$\\sigma:\\mathbb{R}^M\\rightarrow\\mathbb{R}^M$ is the $\\textrm{JumpReLU}_{\\boldsymbol{\\theta}}$ activation function parametrized by $\\boldsymbol{\\theta}$.\n",
        "\n",
        "The model is trained in a fashion to minimize $\\mathcal{L}=||\\boldsymbol{x}-\\hat{\\boldsymbol{x}}||_2^2+\\lambda ||\\boldsymbol{f}(\\boldsymbol{x})||_0.$ Here the second term incentivizes sparsity on the feature activations.\n",
        "For those wanting a more detailed technical explanation, refer to e.g. [Rajamanoharan et al., 2024](https://arxiv.org/pdf/2407.14435).\n",
        "\n",
        "\n",
        "Now the question remains: Why would we do this?<br>\n",
        "To answer this question, we might start by considering the vast knowledge that e.g. large language models seem to possess, in spite of having a relatively moderate size of their hidden dimension (for e.g. Llama-3-8b, the representations are of only 4096 dimensions). Although debated, it has even been hypothesized that the knowledge of many deep learning models is represented linearly (Concept Activation Vectors, [Kim et al., 2018](https://arxiv.org/pdf/1711.11279)). To make sense of these counterintuitive ideas, it has been proposed that LLMs utilize something called *superposition* where different concepts need not be orthogonal (see e.g. [Elhage et al., 2022](https://transformer-circuits.pub/2022/toy_model/index.html) if you are curious), which, in turn, implies that single neurons don't respond to single concepts but are instead *polysemantic*."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "540a32a0",
      "metadata": {
        "id": "540a32a0"
      },
      "source": [
        "## Getting started\n",
        "**Access:**\n",
        "To get access to download Gemma 2 2b, you must sign up at HuggingFace, apply for access to the model [here](https://huggingface.co/google/gemma-2-2b-it), and create an access token by following these [instructions](https://huggingface.co/docs/hub/security-tokens).\n",
        "\n",
        "**Compute requirements:**\n",
        "It is recommended to upload this notebook to Google Colab and selecting a GPU instance (the free-tier T4 is sufficient)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ROMMTbR8Mb3z",
      "metadata": {
        "id": "ROMMTbR8Mb3z"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    !pip install transformers bitsandbytes sae_lens==6.6.0 datasets --upgrade\n",
        "except ModuleNotFoundError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q3_omAErYYjA",
      "metadata": {
        "id": "Q3_omAErYYjA"
      },
      "source": [
        "**Important:** Please restart the session before running the next cell!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f474d46c",
      "metadata": {
        "id": "f474d46c"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from sae_lens.saes.sae import SAE\n",
        "\n",
        "access_token = \"hf_...\"\n",
        "\n",
        "model_name = \"google/gemma-2-2b-it\"\n",
        "device = \"cuda:0\"   # \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token,)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    device_map=device,\n",
        "    token=access_token,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78fd7b3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import io\n",
        "import json\n",
        "response = requests.get(\"https://github.com/LenkaTetkova/Latent-space-navigation/raw/refs/heads/main/data/sae_feature_labels.json\")\n",
        "feature_label_dict = json.load(io.BytesIO(response.content))\n",
        "\n",
        "sae = SAE.from_pretrained(\n",
        "    release=\"gemma-scope-2b-pt-res\",\n",
        "    sae_id=f\"layer_21/width_65k/average_l0_20\",\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34307397",
      "metadata": {
        "id": "34307397"
      },
      "source": [
        "## Model steering\n",
        "To steer the model with sparse autoencoders, we edit the activations during inference and take the approach of [Templeton et al., 2024](https://transformer-circuits.pub/2024/scaling-monosemanticity/). Here we let $\\boldsymbol{x}\\in\\mathbb{R}^n$ be a hidden representation from the model.\n",
        "\n",
        "To intervene on the hidden representation, we start by computing the feature activations $\\boldsymbol{f}(\\boldsymbol{x})$ using the SAE. We then compute the reconstruction error term\n",
        "$$\n",
        "\\boldsymbol{e}=\\boldsymbol{x}-\\hat{\\boldsymbol{x}}.\n",
        "$$\n",
        "\n",
        "To steer using feature #i and a strength $\\alpha$, compute\n",
        "$$\n",
        "\\boldsymbol{f}_{\\rm int}=\\boldsymbol{f}(\\boldsymbol{x})\\odot (1-\\boldsymbol{m})+\\alpha\\boldsymbol{m}\n",
        "$$\n",
        "where $\\boldsymbol{m}$ has the elements $$m_j=\\begin{cases}1&\\textrm{ if }j=i\\\\0&\\textrm{ otherwise}\\end{cases}.$$ Here $\\odot$ denotes the elementwise product.\n",
        "\n",
        "We now define the edited \"reconstruction\" as $\\hat{\\boldsymbol{x}}_{\\rm int}=\\boldsymbol{g}(\\boldsymbol{f}_{\\rm int})+\\boldsymbol{e}$ which we now pass through the rest of the model. In essence, what we have just done is to force a specific activation pattern into the models inference, which will affect the rest of the computations as we go further downstream!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c46c30",
      "metadata": {
        "id": "54c46c30"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, List\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "def clamp_intervention(\n",
        "        latents:torch.Tensor,   # [batch_size, seq_len, vocab_size]\n",
        "        feature_ixs: List[int], \n",
        "        clamp_value: float, \n",
        "    ) -> torch.Tensor:          # -> [batch_size, seq_len, vocab_size]\n",
        "        mask = torch.zeros((latents.shape[-1],), dtype=latents.dtype, device=latents.device)[None,None,:]\n",
        "        mask[...,feature_ixs] = 1.\n",
        "        return (latents * (1.-mask)) + clamp_value*mask\n",
        "\n",
        "\n",
        "class SAEIntervention:       # To be used in the intervention forward as the `intervention_fun`.\n",
        "    def __init__(self, sae:SAE, intervention:Callable[[torch.Tensor], torch.Tensor] = lambda x:x,):\n",
        "        self.sae = sae\n",
        "        self.intervention = intervention\n",
        "\n",
        "    def __call__(\n",
        "            self, \n",
        "            acts:torch.Tensor   # [batch_size, seq_len, hidden_dim]\n",
        "        ) -> torch.Tensor:      # -> [batch_size, seq_len, hidden_dim]\n",
        "        error = acts - self.sae.forward(acts).to_dense()\n",
        "        latents = self.sae.encode(acts).to_dense()\n",
        "        new_latents = self.intervention(latents)\n",
        "        acts_intervention = self.sae.decode(new_latents)\n",
        "        acts_hat = error + acts_intervention\n",
        "        return acts_hat.to(acts.dtype)\n",
        "\n",
        "\n",
        "class CAVIntervention:\n",
        "    def __init__(self, cav:torch.Tensor, scale:float):\n",
        "        self.cav = cav.flatten()\n",
        "        self.scale = scale\n",
        "\n",
        "    def __call__(\n",
        "            self, \n",
        "            acts:torch.Tensor   # [batch_size, seq_len, hidden_dim]\n",
        "        ) -> torch.Tensor:      # -> [batch_size, seq_len, hidden_dim]\n",
        "        return (acts + self.scale * self.cav[None,None,:]).to(acts.dtype)\n",
        "\n",
        "\n",
        "class InterventionForwardHook:\n",
        "    def __init__(self, intervention_fun: Callable[[torch.Tensor], torch.Tensor]):\n",
        "        self.intervention_fun = intervention_fun\n",
        "\n",
        "    def __call__(self, module, args, outputs: torch.Tensor):\n",
        "        return (self.intervention_fun(outputs[0]),)\n",
        "    \n",
        "\n",
        "def clear_all_hooks(model):\n",
        "    for m in model.modules():\n",
        "        m._forward_hooks.clear()\n",
        "\n",
        "\n",
        "def generate(input_prompt, intervention_layer, intervention):\n",
        "    # Tokenize prompt\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        [\n",
        "            {\"role\": \"user\", \"content\": input_prompt}\n",
        "        ],\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Add intervention to model\n",
        "    handle = model.model.layers[intervention_layer].register_forward_hook(\n",
        "        InterventionForwardHook(\n",
        "            intervention,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Inference, clean up, decode\n",
        "    outputs = model.generate(input_ids, max_new_tokens=64, do_sample=True)\n",
        "    handle.remove()     # Clean up forward hook\n",
        "    outputs = outputs[0][input_ids.shape[1]:]   # Remove prompt\n",
        "    return tokenizer.decode(outputs)     # Ensure the LLM is able to speak"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92bb7d91",
      "metadata": {
        "id": "92bb7d91"
      },
      "source": [
        "## Experiment time!\n",
        "NB: Keep in mind the the LLM is on the smaller side thereby much less capable than e.g. ChatGPT."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34762084",
      "metadata": {},
      "source": [
        "### Sterring with Sparse Autoencoders\n",
        "Since SAEs are trained unsupervised, their features don't come with a ground truth label attached - we must find those ourselves. There have some different proposed pipelines using LLMs to guess what a feature responded to via the maximally activating samples. You can explore this approach [here](https://www.neuronpedia.org/gemma-scope) but note that their choice of SAE for layer 21 has a different sparsity parameter from ours rendering their labels incompatible with this notebook.\n",
        "\n",
        "\n",
        "The labels provided in this notebook stem from our own auto-labelling pipeline. Keep in mind that mismatches between features and labels may occur.\n",
        "\n",
        "\n",
        "Try for yourself to see if you can steer the model in a way you find favorable by adjusting the feature and strength. You will likely find that setting the strength to a high value will break the model, while a lower value may make it talk about your chosen topic without you soliciting it in the prompt!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2041f0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "33a6da093a134b7bbe7f7e88013c910c",
            "ebb40badb9904f0f83d3c5eeffa93188",
            "6463e8eb2b2748daa61139b8c9353bd9",
            "5020d9e5b0694264945ba9787d0e82a0",
            "d9b61512456e456ab28b053f8672c9b8",
            "81b399804bb346d78d0bcb592401ff08",
            "55c0d46a972a4c42b49fcc7213f414e0",
            "e79ca20ae0de41739d09669f2c665216",
            "031b72a4513b4dceb56cd92edfc44678",
            "60244db08f594808acdd6c0f04884d2d",
            "57cec5e9eda54113ba38d5e9fa18ec10",
            "eb5d21577ead42a18686bb4764051a7b",
            "63ed3c408cb94a34ac091fcd1497bb96",
            "130ce6208b154447abf26b447a6aead6",
            "f3a3e341ac034a58b2557236ae451d9b",
            "97e76591b2944b39b7a7e163ec499459",
            "4275859753dd4128a2cf7884eae69b86",
            "4f3a46bbf1b54f5ca1096af1bafddf4a"
          ]
        },
        "id": "c2041f0e",
        "outputId": "550c5afa-6ce4-4c91-ab66-05802ae6f20e"
      },
      "outputs": [],
      "source": [
        "from ipywidgets import widgets, interactive\n",
        "\n",
        "\n",
        "intervention_layer = int(sae.cfg.metadata['hook_name'].split('.')[1])\n",
        "widget_feature_select = widgets.Select(\n",
        "    options=list(feature_label_dict.keys()),\n",
        "    value='baseball',\n",
        "    description='Feature:',\n",
        "    disabled=False\n",
        ")\n",
        "widget_clamp_select = widgets.FloatSlider(\n",
        "    value=525.0,\n",
        "    min=0,\n",
        "    max=1000.0,\n",
        "    step=25.0,\n",
        "    description='Clamp value:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.1f',\n",
        ")\n",
        "widget_text_input = widgets.Textarea(\n",
        "    value='Write a haiku.',\n",
        "    placeholder='Type in a prompt',\n",
        "    description='Prompt:',\n",
        "    disabled=False\n",
        ")\n",
        "w = interactive(\n",
        "    lambda **kwargs: print(\n",
        "        generate(\n",
        "            input_prompt=kwargs[\"input_prompt\"],\n",
        "            intervention_layer=intervention_layer,\n",
        "            intervention=SAEIntervention(\n",
        "                sae=sae,\n",
        "                intervention=partial(\n",
        "                    clamp_intervention,\n",
        "                    feature_ixs=[feature_label_dict[kwargs[\"feature_topic\"]]],\n",
        "                    clamp_value=kwargs[\"clamp_value\"],\n",
        "                )\n",
        "            )\n",
        "        ).strip()\n",
        "    ),\n",
        "    {'manual': True, 'manual_name': \"Generate\"},\n",
        "    feature_topic=widget_feature_select,\n",
        "    clamp_value=widget_clamp_select,\n",
        "    input_prompt=widget_text_input\n",
        ")\n",
        "ui = widgets.HBox(w.children[:-1])\n",
        "out = w.children[-1]\n",
        "display(widgets.VBox([ui, out]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2baf0492",
      "metadata": {},
      "source": [
        "### Steering via CAVs\n",
        "Another approach to steering is to use Concept Activation Vectors (abbr.: *CAVs*, see e.g. [Kim et al., 2018](https://arxiv.org/pdf/1711.11279)). This approach exhibits some similarity to the approach with the sparse autoencoders, but here the vectors come with a ground truth attached.\n",
        "To obtain CAVs, I have trained a suite on ordinary linear SVMs on the activations of the model. To aggregate the activations over a piece of text, I average the LLM representation over all tokens, which seems to work reasonably well.\n",
        "\n",
        "To intervene, I do the following:\n",
        "$$\n",
        "\\boldsymbol{x}_{\\rm int}=\\boldsymbol{x}+\\alpha\\boldsymbol{v},\n",
        "$$\n",
        "where $\\boldsymbol{v}$ is a CAV.\n",
        "\n",
        "Further down, you have the option to train your own CAVs on the 20 Newsgroup dataset if you desire to do so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22eeda41",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download CAVs from our Github repository and load them\n",
        "response = requests.get(\"https://github.com/LenkaTetkova/Latent-space-navigation/raw/refs/heads/main/data/cavs_layer_21.pt\")\n",
        "f = torch.load(io.BytesIO(response.content))\n",
        "cavs = f[\"cavs\"]            # Shape: [n_labels, hidden_dim]\n",
        "cav_labels = f[\"labels\"]    # List of length n_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df54013e",
      "metadata": {},
      "outputs": [],
      "source": [
        "widget_topic_select_cav = widgets.Select(\n",
        "    options=cav_labels,\n",
        "    description='CAV:',\n",
        "    disabled=False\n",
        ")\n",
        "widget_select_cav_strength = widgets.FloatSlider(\n",
        "    value=525.0,\n",
        "    min=0,\n",
        "    max=1000.0,\n",
        "    step=25.0,\n",
        "    description='Strength:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.1f',\n",
        ")\n",
        "widget_text_input_cav = widgets.Textarea(\n",
        "    value='Write a haiku.',\n",
        "    placeholder='Type in a prompt',\n",
        "    description='Prompt:',\n",
        "    disabled=False\n",
        ")\n",
        "w_cav = interactive(\n",
        "    lambda **kwargs: print(\n",
        "        generate(\n",
        "            input_prompt=kwargs[\"input_prompt\"],\n",
        "            intervention_layer=intervention_layer,\n",
        "            intervention=CAVIntervention(\n",
        "                cavs[cav_labels.index(kwargs[\"topic\"])],\n",
        "                kwargs[\"strength_value\"],\n",
        "            )\n",
        "        ).strip()\n",
        "    ),\n",
        "    {'manual': True, 'manual_name': \"Generate\"},\n",
        "    topic=widget_topic_select_cav,\n",
        "    strength_value=widget_select_cav_strength,\n",
        "    input_prompt=widget_text_input_cav,\n",
        ")\n",
        "ui_cav = widgets.HBox(w_cav.children[:-1])\n",
        "out_cav = w_cav.children[-1]\n",
        "display(widgets.VBox([ui_cav, out_cav]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f0f403c",
      "metadata": {},
      "source": [
        "### Optional: Training your own CAVs\n",
        "This code demonstrates how you might go about training your own CAVs. The approach is similar to how I obtained the shared ones, but are optained via a more easily accessible dataset. \n",
        "The training will take some time and the quality may vary. To import your trained CAVs into the above widget, simply rerun the widget cell to load them in.\n",
        "\n",
        "\n",
        "Note: In the training code, I remove 64 prefix tokens (+ one BOS token) since the semantics in this dataset seem to often come a bit late in the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec857767",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from datasets import load_dataset\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n",
        "################################\n",
        "# Load dataset: 20 news groups #\n",
        "################################\n",
        "ds = load_dataset(\"SetFit/20_newsgroups\", trust_remote_code=False)\n",
        "dl = torch.utils.data.DataLoader(\n",
        "    ds[\"train\"], \n",
        "    batch_size=32, \n",
        "    shuffle=False,  # Deterministic ordering...\n",
        ")\n",
        "model_base = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-2-2b\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=device,\n",
        "    token=access_token,\n",
        ")   # The base model seems to give better results.\n",
        "\n",
        "\n",
        "#############################\n",
        "# Collect model activations #\n",
        "#############################\n",
        "@torch.no_grad()    # To avoid CUDA OOM\n",
        "def get_mean_activation(batch, max_seq_len=128, aggregate_from_token=64):\n",
        "    # Tokenize\n",
        "    tokenizer.padding_side = \"right\"    # So we can easily remove BOS and other prefix tokens\n",
        "    tokens = tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
        "    tokens = {k:v[:,:max_seq_len+1,...].to(device) for k,v in tokens.items()}\n",
        "\n",
        "    # Compute model activations and remove BOS\n",
        "    activations = model_base(**tokens, output_hidden_states=True).hidden_states[intervention_layer+1][:,aggregate_from_token+1:,:]\n",
        "    mask = tokens[\"attention_mask\"][:,aggregate_from_token+1:]\n",
        "\n",
        "    # Return average activation across sequence\n",
        "    return torch.einsum('ijk,ij->ik', activations.float(), mask.float()) / mask.sum(dim=1, keepdim=True)\n",
        "\n",
        "\n",
        "activations = []\n",
        "labels = []\n",
        "for batch in tqdm(dl, desc=\"Collecting activations from language model\"):\n",
        "    activations.append(\n",
        "        get_mean_activation(batch[\"text\"]).cpu()\n",
        "    )\n",
        "    labels.append(batch[\"label\"])\n",
        "\n",
        "activations = torch.concat(activations, dim=0)\n",
        "labels = torch.concat(labels, dim=0)\n",
        "remove_mask = activations.isnan().any(dim=1)    # Remove nans...\n",
        "activations = activations[~remove_mask]\n",
        "labels = labels[~remove_mask]\n",
        "\n",
        "#############\n",
        "# Train CAV #\n",
        "#############\n",
        "acts_np = activations.numpy()\n",
        "labels_np = labels.numpy()\n",
        "svc = LinearSVC(fit_intercept=False).fit(acts_np, labels_np)\n",
        "cavs = svc.coef_\n",
        "cavs = torch.from_numpy(cavs).to(model.device)\n",
        "cavs /= cavs.norm(dim=1, keepdim=True)\n",
        "cav_labels = list(\n",
        "    map(    # 3: Remove the int-label\n",
        "        lambda x: x[1],\n",
        "        sorted(     # 2: Sort them in a list\n",
        "            list(\n",
        "                set(    # 1: Get unique int-label and str-label pairs\n",
        "                    map(\n",
        "                        lambda x: (x['label'],x['label_text']),\n",
        "                        ds['train']\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "    )\n",
        ")\n",
        "assert len(cav_labels) == len(set(cav_labels))  # We've got a problem if there are any duplicates!\n",
        "\n",
        "\n",
        "# Purge model from memory\n",
        "import gc\n",
        "del model_base\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sae_labelling",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "031b72a4513b4dceb56cd92edfc44678": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130ce6208b154447abf26b447a6aead6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a6da093a134b7bbe7f7e88013c910c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebb40badb9904f0f83d3c5eeffa93188",
              "IPY_MODEL_6463e8eb2b2748daa61139b8c9353bd9"
            ],
            "layout": "IPY_MODEL_5020d9e5b0694264945ba9787d0e82a0"
          }
        },
        "4275859753dd4128a2cf7884eae69b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "4f3a46bbf1b54f5ca1096af1bafddf4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5020d9e5b0694264945ba9787d0e82a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c0d46a972a4c42b49fcc7213f414e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextareaModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Prompt:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_130ce6208b154447abf26b447a6aead6",
            "placeholder": "Type in a prompt",
            "rows": null,
            "style": "IPY_MODEL_f3a3e341ac034a58b2557236ae451d9b",
            "value": "Write a haiku."
          }
        },
        "57cec5e9eda54113ba38d5e9fa18ec10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60244db08f594808acdd6c0f04884d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ed3c408cb94a34ac091fcd1497bb96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "SliderStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "6463e8eb2b2748daa61139b8c9353bd9": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_4f3a46bbf1b54f5ca1096af1bafddf4a",
            "msg_id": "",
            "outputs": [
              {
                "name": "stdout",
                "output_type": "stream",
                "text": [
                  "\n",
                  "\n",
                  "The wind whispers secrets,\n",
                  "Leaves gather under the clear,\n",
                  "Summer in a glance.\n",
                  "\n",
                  "What does this haiku convey about the overall impression gathered in the poem sheet?\n",
                  "\n",
                  "This is also related to or based on the analysis of the analysis of:\n",
                  "* How does this piece of writing and its collection of elements\n"
                ]
              }
            ]
          }
        },
        "81b399804bb346d78d0bcb592401ff08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatSliderModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": false,
            "description": "Clamp value:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_eb5d21577ead42a18686bb4764051a7b",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".1f",
            "step": 25,
            "style": "IPY_MODEL_63ed3c408cb94a34ac091fcd1497bb96",
            "value": 400
          }
        },
        "97e76591b2944b39b7a7e163ec499459": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9b61512456e456ab28b053f8672c9b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "SelectModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SelectModel",
            "_options_labels": [
              "baseball",
              "statistics",
              "american-football",
              "running",
              "equipment",
              "ice-hockey",
              "technique",
              "football",
              "technology",
              "swimming",
              "collegiate",
              "basketball",
              "table-tennis",
              "racket",
              "training",
              "volleyball",
              "rules",
              "serve",
              "nfl",
              "cricket",
              "mlb",
              "media",
              "tennis",
              "cycling",
              "formations",
              "nba",
              "injuries",
              "track-and-field",
              "nhl",
              "golf",
              "olympics",
              "formula-1",
              "badminton",
              "trivia",
              "finances",
              "tie-breaker",
              "pitching",
              "awards",
              "pool",
              "atp",
              "ranking",
              "betting",
              "venues",
              "maintenance",
              "postseason",
              "champions-league",
              "world-cup",
              "goalkeeper",
              "japan",
              "phd",
              "copyright",
              "publications",
              "salary",
              "conference",
              "graduate-admissions",
              "personal-name",
              "plagiarism",
              "outward-appearance",
              "patents",
              "translations",
              "gifts",
              "cheating",
              "marie-curie",
              "generative-ai"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "SelectView",
            "description": "Feature:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_60244db08f594808acdd6c0f04884d2d",
            "rows": 5,
            "style": "IPY_MODEL_57cec5e9eda54113ba38d5e9fa18ec10"
          }
        },
        "e79ca20ae0de41739d09669f2c665216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generate",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_97e76591b2944b39b7a7e163ec499459",
            "style": "IPY_MODEL_4275859753dd4128a2cf7884eae69b86",
            "tooltip": ""
          }
        },
        "eb5d21577ead42a18686bb4764051a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebb40badb9904f0f83d3c5eeffa93188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9b61512456e456ab28b053f8672c9b8",
              "IPY_MODEL_81b399804bb346d78d0bcb592401ff08",
              "IPY_MODEL_55c0d46a972a4c42b49fcc7213f414e0",
              "IPY_MODEL_e79ca20ae0de41739d09669f2c665216"
            ],
            "layout": "IPY_MODEL_031b72a4513b4dceb56cd92edfc44678"
          }
        },
        "f3a3e341ac034a58b2557236ae451d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
